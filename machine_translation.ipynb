{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4o7oqjbKGfE",
        "outputId": "b0c73a0a-e40c-4422-94f0-bee7705a4197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TVlArBU_i4Pn"
      },
      "outputs": [],
      "source": [
        "# Import dependencies\n",
        "import pandas as pd\n",
        "from string import punctuation\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_SOo6YH681Pt"
      },
      "outputs": [],
      "source": [
        "# Set up paths\n",
        "DATA_FILEPATH = \"/content/drive/MyDrive/Language_Translation/data.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNrsa-cY_pjY",
        "outputId": "b078e0fb-d3f9-4132-af89-3aee14ac7cf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-09-05 13:37:35--  https://raw.githubusercontent.com/GargPriyanshu1112/Neural-Machine-Translation/main/attention_mechanism.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2644 (2.6K) [text/plain]\n",
            "Saving to: ‘attention_mechanism.py’\n",
            "\n",
            "\rattention_mechanism   0%[                    ]       0  --.-KB/s               \rattention_mechanism 100%[===================>]   2.58K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-05 13:37:35 (57.2 MB/s) - ‘attention_mechanism.py’ saved [2644/2644]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download attention_mechanism.py\n",
        "!wget https://raw.githubusercontent.com/GargPriyanshu1112/Neural-Machine-Translation/main/attention_mechanism.py\n",
        "\n",
        "from attention_mechanism import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbbKPqiU8vRd"
      },
      "source": [
        "# Load in the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "C5lXXDSWdlGH"
      },
      "outputs": [],
      "source": [
        "def load_doc(filepath, mode):\n",
        "    file = open(filepath, mode)\n",
        "    content = file.read()\n",
        "    file.close()\n",
        "\n",
        "    return content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Zju68l2qdn06"
      },
      "outputs": [],
      "source": [
        "def get_pairs(filepath):\n",
        "    inputs, targets = [], []\n",
        "\n",
        "    # Get file contents\n",
        "    content = load_doc(filepath, 'r')\n",
        "    \n",
        "    # Get sentence pairs\n",
        "    for line in content.split('\\n'):\n",
        "        if len(line) < 1:\n",
        "            continue\n",
        "\n",
        "        inp, tar, _ = line.split('\\t')\n",
        "        inputs.append(inp)\n",
        "        targets.append(tar)\n",
        "\n",
        "\n",
        "    data = pd.DataFrame({'inputs': inputs,\n",
        "                         'targets': targets})        \n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uojG9LLufA0b",
        "outputId": "cb85ed2d-e906-4c4e-a5b9-0b08866057cc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d9f6e334-f0d8-4a5f-aaf7-9894d8e95902\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs</th>\n",
              "      <th>targets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5833</th>\n",
              "      <td>Love is crazy.</td>\n",
              "      <td>El amor es una locura.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135111</th>\n",
              "      <td>If you ever want to get better, you have to ta...</td>\n",
              "      <td>Si quieres mejorarte algún día, tienes que tom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85682</th>\n",
              "      <td>I am very grateful for your help.</td>\n",
              "      <td>Estoy muy agradecido por tu ayuda.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121460</th>\n",
              "      <td>I asked Tom if I could talk to him in private.</td>\n",
              "      <td>Le pregunté a Tom si podía hablarle en privado.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107187</th>\n",
              "      <td>Just this once, I'll make an exception.</td>\n",
              "      <td>Haré una excepción solo por esta vez.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9f6e334-f0d8-4a5f-aaf7-9894d8e95902')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d9f6e334-f0d8-4a5f-aaf7-9894d8e95902 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d9f6e334-f0d8-4a5f-aaf7-9894d8e95902');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   inputs  \\\n",
              "5833                                       Love is crazy.   \n",
              "135111  If you ever want to get better, you have to ta...   \n",
              "85682                   I am very grateful for your help.   \n",
              "121460     I asked Tom if I could talk to him in private.   \n",
              "107187            Just this once, I'll make an exception.   \n",
              "\n",
              "                                                  targets  \n",
              "5833                               El amor es una locura.  \n",
              "135111  Si quieres mejorarte algún día, tienes que tom...  \n",
              "85682                  Estoy muy agradecido por tu ayuda.  \n",
              "121460    Le pregunté a Tom si podía hablarle en privado.  \n",
              "107187              Haré una excepción solo por esta vez.  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load in the data\n",
        "data = get_pairs(DATA_FILEPATH).sample(70000)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHatondO_Rsh",
        "outputId": "85d7c30d-9bbc-45d2-9703-f0aade8917bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 70000 entries, 5833 to 41854\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   inputs   70000 non-null  object\n",
            " 1   targets  70000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.6+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "L56Hsgt8KgzZ"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "max_len = 30\n",
        "enc_units = 1024\n",
        "dec_units = 1024\n",
        "embedding_dim = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH7gI4BJ_w0V"
      },
      "source": [
        "# Preprocess the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GX1rfvjvB0sI"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text= re.sub(\"'\", '', text)\n",
        "    text = re.sub(r\"\\d\", '', text)\n",
        "    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)    \n",
        "    text = re.sub(\"\\s+\", ' ',  text).strip()\n",
        "    text=  'startseq ' + text + ' endseq'\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Yf70_f8VOOwy"
      },
      "outputs": [],
      "source": [
        "# Preprocess inputs (English sentences)\n",
        "data[\"inputs\"] = data[\"inputs\"].apply(lambda x: preprocess_text(x))\n",
        "\n",
        "# Preprocess targets (Spanish sentences)\n",
        "data[\"targets\"] = data[\"targets\"].apply(lambda x: preprocess_text(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuRl2PdoRI8U"
      },
      "source": [
        "# Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSwIf22aPlyN",
        "outputId": "89adfd97-730e-4849-858a-a51d12ef796e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training samples : 56000\n",
            "Number of test samples     : 14000\n"
          ]
        }
      ],
      "source": [
        "train_inp, test_inp, train_tar, test_tar = train_test_split(data.inputs, data.targets,\n",
        "                                                            test_size=0.2,\n",
        "                                                            random_state=42)\n",
        "\n",
        "print(f\"Number of training samples : {len(train_inp)}\")\n",
        "print(f\"Number of test samples     : {len(test_inp)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSmCj1I4nKD-"
      },
      "source": [
        "# Tokenize and Pad the Sentences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pSOTM2P_Sj93"
      },
      "outputs": [],
      "source": [
        "class LanguageIndex():\n",
        "    def __init__(self, sentences_list):\n",
        "        self.tokenizer = None\n",
        "        self.word2idx  = None\n",
        "\n",
        "        self.get_tokenizer(sentences_list)\n",
        "        self.get_word_to_idx_mapping()\n",
        "\n",
        "\n",
        "    def get_tokenizer(self, sentences_list):\n",
        "        self.tokenizer = Tokenizer(filters='', oov_token=\"<UNK>\")\n",
        "        self.tokenizer.fit_on_texts(sentences_list)\n",
        "\n",
        "    def get_word_to_idx_mapping(self):\n",
        "        self.word2idx = self.tokenizer.word_index\n",
        "\n",
        "\n",
        "    def get_max_length(self, sentences):\n",
        "        return max([len(line.split())  for line in sentences])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2dDue4FzDM20"
      },
      "outputs": [],
      "source": [
        "input_lang  = LanguageIndex([line  for line in data.inputs])\n",
        "target_lang = LanguageIndex([line  for line in data.targets])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBx5QpNOA-MH",
        "outputId": "0d146615-a384-4c6f-e1fe-df139b1f049e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of the longest input (English) sentence : 53\n",
            "Length of the longest target (Spanish) sentence : 59\n"
          ]
        }
      ],
      "source": [
        "print(f\"Length of the longest input (English) sentence : {input_lang.get_max_length(data.inputs)}\")\n",
        "print(f\"Length of the longest target (Spanish) sentence : {target_lang.get_max_length(data.targets)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "m5y7yo9IDkG0"
      },
      "outputs": [],
      "source": [
        "# Tokenize input sentences\n",
        "input_seqs_int = input_lang.tokenizer.texts_to_sequences(train_inp)\n",
        "# Pad input sentences\n",
        "input_seqs_int = pad_sequences(input_seqs_int, maxlen=max_len,  padding=\"post\")  \n",
        "\n",
        "\n",
        "# Tokenize target sentences\n",
        "target_seqs_int = target_lang.tokenizer.texts_to_sequences(train_tar) \n",
        "# Pad target sentences\n",
        "target_seqs_int = pad_sequences(target_seqs_int, maxlen=max_len, padding=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQcWQKYeIjOS",
        "outputId": "5fb8aba5-d160-4759-9054-59b87f35896f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size for inputs (English sentences)  : 11301\n",
            "Vocab size for targets (Spanish sentences) : 21076\n"
          ]
        }
      ],
      "source": [
        "input_vocab_size = len(input_lang.word2idx) + 1\n",
        "target_vocab_size = len(target_lang.word2idx) + 1\n",
        "\n",
        "print(f\"Vocab size for inputs (English sentences)  : {input_vocab_size}\")\n",
        "print(f\"Vocab size for targets (Spanish sentences) : {target_vocab_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k05NGYaGp5F"
      },
      "source": [
        "# Create Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "czfD4a_304PW"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xwu8_wXRFw4H"
      },
      "outputs": [],
      "source": [
        "def get_training_dataset(X_train, y_train, batch_size):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Yk8DLk9pFwy3"
      },
      "outputs": [],
      "source": [
        "# Get train dataset\n",
        "train_dataset = get_training_dataset(input_seqs_int, target_seqs_int, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyp_6iXUrbW0"
      },
      "source": [
        "# Define Optimizer and Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mINuipEsI4Yd"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "\n",
        "# Loss function\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction=\"none\")\n",
        "\n",
        "def loss_func(actual_words, predicted_words_probability):\n",
        "\tloss = loss_object(actual_words, predicted_words_probability)\n",
        "\tmask = tf.where(actual_words > 0, 1.0, 0.0)\n",
        "\treturn tf.reduce_sum(mask * loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpnHdyKCO7x4"
      },
      "source": [
        "# Get Model Encoder, Decoder and Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2bG6KBBqKs46"
      },
      "outputs": [],
      "source": [
        "# Get the encoder\n",
        "encoder = Encoder(input_vocab_size, embedding_dim, enc_units, BATCH_SIZE)\n",
        "\n",
        "# Get the attention layer\n",
        "attention_layer = BahdanauAttention(10)\n",
        "\n",
        "# Get the decoder\n",
        "decoder = Decoder(target_vocab_size, embedding_dim, dec_units, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVFPLdZ3PnlO"
      },
      "source": [
        "# Establish Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IxnZE6GSCT00"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = \"training_checkpoints\"\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "busfdruciDw4"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "raufrNGTzz9L"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ANCa9yLJuLjw"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(input, target, enc_hidden_state):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_hidden_states, enc_output_state = encoder(input, enc_hidden_state)\n",
        "        # The last consolidated encoder hidden state is fed as input to the first\n",
        "        # time step of the decoder.\n",
        "        dec_hidden_state = enc_output_state\n",
        "\n",
        "        # Set decoder input to be: 'startseq'  \n",
        "        # which is the ground truth for 0th time step\n",
        "        dec_input = tf.expand_dims([target_lang.word2idx['startseq']] * BATCH_SIZE, axis=1)\n",
        "\n",
        "        # Loop through each timestep\n",
        "        for t in range(1, target.shape[1]): \n",
        "            # dec_input : ground truth from the previous timestep\n",
        "            # dec_hidden_state : hidden state of the decoder from previous timestep\n",
        "            predictions, dec_hidden_state, _ = decoder(dec_input, enc_hidden_states, dec_hidden_state)\n",
        "\n",
        "            # Calcuate loss for current time step and add it to get loss for all time steps\n",
        "            loss += loss_func(target[:, t], predictions) \n",
        "\n",
        "            # Set the ground truth as the next input of the decoder\n",
        "            dec_input = tf.expand_dims(target[:, t], axis=1)\n",
        "\n",
        "\n",
        "    # Calculate batch loss\n",
        "    batch_loss = loss / int(target.shape[1])\n",
        "\n",
        "    # Get the trainable variables\n",
        "    trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    \n",
        "    # Derive gradients\n",
        "    gradients = tape.gradient(loss, trainable_variables)\n",
        "    \n",
        "    # Apply gradients\n",
        "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "\n",
        "    return batch_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKHoJjKfwsAI",
        "outputId": "b890b62d-d0ca-429d-b3b5-0ac8e0eccb6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1,  Loss 85.8733\n",
            "Time taken for epoch 1 : 326.3 sec\n",
            "\n",
            "Epoch 2,  Loss 59.1122\n",
            "Time taken for epoch 2 : 284.9 sec\n",
            "\n",
            "Epoch 3,  Loss 41.9043\n",
            "Time taken for epoch 3 : 285.2 sec\n",
            "\n",
            "Epoch 4,  Loss 30.7302\n",
            "Time taken for epoch 4 : 285.0 sec\n",
            "\n",
            "Epoch 5,  Loss 23.2487\n",
            "Time taken for epoch 5 : 285.4 sec\n",
            "\n",
            "Epoch 6,  Loss 17.9024\n",
            "Time taken for epoch 6 : 285.0 sec\n",
            "\n",
            "Epoch 7,  Loss 14.4215\n",
            "Time taken for epoch 7 : 285.0 sec\n",
            "\n",
            "Epoch 8,  Loss 11.8645\n",
            "Time taken for epoch 8 : 284.9 sec\n",
            "\n",
            "Epoch 9,  Loss 9.6212\n",
            "Time taken for epoch 9 : 285.2 sec\n",
            "\n",
            "Epoch 10,  Loss 8.3704\n",
            "Time taken for epoch 10 : 285.2 sec\n",
            "\n",
            "Epoch 11,  Loss 6.9312\n",
            "Time taken for epoch 11 : 284.7 sec\n",
            "\n",
            "Epoch 12,  Loss 5.4692\n",
            "Time taken for epoch 12 : 284.6 sec\n",
            "\n",
            "Epoch 13,  Loss 4.8627\n",
            "Time taken for epoch 13 : 284.7 sec\n",
            "\n",
            "Epoch 14,  Loss 3.9157\n",
            "Time taken for epoch 14 : 284.8 sec\n",
            "\n",
            "Epoch 15,  Loss 3.5573\n",
            "Time taken for epoch 15 : 284.8 sec\n",
            "\n",
            "Epoch 16,  Loss 2.9082\n",
            "Time taken for epoch 16 : 284.7 sec\n",
            "\n",
            "Epoch 17,  Loss 2.6923\n",
            "Time taken for epoch 17 : 284.7 sec\n",
            "\n",
            "Epoch 18,  Loss 2.2101\n",
            "Time taken for epoch 18 : 284.7 sec\n",
            "\n",
            "Epoch 19,  Loss 2.1383\n",
            "Time taken for epoch 19 : 284.6 sec\n",
            "\n",
            "Epoch 20,  Loss 2.2218\n",
            "Time taken for epoch 20 : 284.6 sec\n",
            "\n",
            "Epoch 21,  Loss 1.9474\n",
            "Time taken for epoch 21 : 284.4 sec\n",
            "\n",
            "Epoch 22,  Loss 1.9167\n",
            "Time taken for epoch 22 : 284.8 sec\n",
            "\n",
            "Epoch 23,  Loss 1.3918\n",
            "Time taken for epoch 23 : 284.6 sec\n",
            "\n",
            "Epoch 24,  Loss 1.7589\n",
            "Time taken for epoch 24 : 284.4 sec\n",
            "\n",
            "Epoch 25,  Loss 1.9845\n",
            "Time taken for epoch 25 : 284.5 sec\n",
            "\n",
            "Epoch 26,  Loss 1.4661\n",
            "Time taken for epoch 26 : 284.5 sec\n",
            "\n",
            "Epoch 27,  Loss 1.3276\n",
            "Time taken for epoch 27 : 284.5 sec\n",
            "\n",
            "Epoch 28,  Loss 1.3427\n",
            "Time taken for epoch 28 : 284.5 sec\n",
            "\n",
            "Epoch 29,  Loss 1.3794\n",
            "Time taken for epoch 29 : 284.7 sec\n",
            "\n",
            "Epoch 30,  Loss 1.2720\n",
            "Time taken for epoch 30 : 286.3 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Initialize encoder hidden state\n",
        "    enc_hidden_state = encoder.initialize_hidden_state()\n",
        "\n",
        "    loss_values = [] # Will store loss value for each batch in an epoch\n",
        "\n",
        "    for batch, (input, target) in enumerate(train_dataset):\n",
        "        batch_loss = train_step(input, target, enc_hidden_state)\n",
        "        loss_values.append(batch_loss)\n",
        "\n",
        "\n",
        "    # Save checkpoints every 10 epochs\n",
        "    if (epoch == EPOCHS-1):\n",
        "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "    print(f\"Epoch {epoch+1},  Loss {np.mean(loss_values):.4f}\")\n",
        "    print(f\"Time taken for epoch {epoch+1} : {(time.time() - start_time):.1f} sec\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDB6vmChtvXX"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "YVVka7-xeJYX"
      },
      "outputs": [],
      "source": [
        "def translate_text(input_text):\n",
        "\n",
        "    # Preprocess the text\n",
        "    text = preprocess_text(input_text)\n",
        "    # Tokenize and pad the text\n",
        "    text = [input_lang.word2idx[word]  for word in text.split()]\n",
        "    text = pad_sequences([text], maxlen=max_len, padding=\"post\")\n",
        "    text = tf.convert_to_tensor(text)\n",
        "\n",
        "    enc_hidden_state = tf.zeros((1, enc_units))\n",
        "    enc_hidden_states, enc_output_state = encoder(text, enc_hidden_state)\n",
        "    \n",
        "    dec_hidden_state = enc_output_state\n",
        "    dec_input = tf.expand_dims([target_lang.word2idx['startseq']], axis=1)\n",
        "\n",
        "    output_text = ''\n",
        "    for t in range(1, max_len):\n",
        "        predictions, dec_hidden_state, attention_weights = decoder(dec_input,\n",
        "                                                                   enc_hidden_states,\n",
        "                                                                   dec_hidden_state)\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        output_text += target_lang.tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        if target_lang.tokenizer.index_word[predicted_id] == 'endseq':\n",
        "            return output_text\n",
        "        else:\n",
        "            # Feed the predicted ID back into the model\n",
        "            dec_input = tf.expand_dims([predicted_id], 0)        \n",
        "\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNKXUXAVeZm-",
        "outputId": "ca44bd7e-8800-4bda-d9f5-8ad5f7613b80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English Text        : i dont know what i want .\n",
            "\n",
            "Machine Translation : no sé qué me quiero .\n",
            "Correct Translation : no sé lo que quiero .\n",
            "\n",
            "-------------------------------------------------------------------\n",
            "\n",
            "\n",
            "English Text        : im your boyfriend , arent i ?\n",
            "\n",
            "Machine Translation : ¿ soy tu novio , ¿ no ?\n",
            "Correct Translation : soy tu novio , ¿ o no ?\n",
            "\n",
            "-------------------------------------------------------------------\n",
            "\n",
            "\n",
            "English Text        : tell me the truth .\n",
            "\n",
            "Machine Translation : decídmelo a la verdad .\n",
            "Correct Translation : decidme la verdad .\n",
            "\n",
            "-------------------------------------------------------------------\n",
            "\n",
            "\n",
            "English Text        : what makes you think that isnt true ?\n",
            "\n",
            "Machine Translation : ¿ qué te hace pensar que eso no es verdad ?\n",
            "Correct Translation : ¿ qué te hace pensar que eso no es cierto ?\n",
            "\n",
            "-------------------------------------------------------------------\n",
            "\n",
            "\n",
            "English Text        : i can only tell you what i know .\n",
            "\n",
            "Machine Translation : puedo saber decirte lo que sé .\n",
            "Correct Translation : sólo te puedo decir lo que sé .\n",
            "\n",
            "-------------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    rand_idx = random.choice(test_inp.index)\n",
        "    print(f\"English Text        : {' '.join(test_inp[rand_idx].split()[1:-1])}\\n\")\n",
        "    print(f\"Machine Translation : {' '.join(translate_text(test_inp[rand_idx]).split()[:-1])}\")\n",
        "    print(f\"Correct Translation : {' '.join(test_tar[rand_idx].split()[1:-1])}\")\n",
        "    print(\"\\n-------------------------------------------------------------------\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
